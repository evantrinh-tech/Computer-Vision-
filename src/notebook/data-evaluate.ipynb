{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0455bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ƒêang qu√©t 127 ·∫£nh trong d:\\Computer Vision\\Computer-Vision Project\\Computer-Vision-\\data\\images\\normal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:00<00:00, 187.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kh√¥ng t√¨m th·∫•y ·∫£nh tr√πng l·∫∑p!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dhash(image, hash_size=8):\n",
    "    \"\"\"\n",
    "    T√≠nh to√°n hash c·ªßa ·∫£nh d·ª±a tr√™n ch√™nh l·ªách gradient (Difference Hash).\n",
    "    C√°ch n√†y hi·ªáu qu·∫£ h∆°n Average Hash trong vi·ªác t√¨m ·∫£nh t∆∞∆°ng ƒë·ªìng.\n",
    "    \"\"\"\n",
    "    # 1. Resize v√† chuy·ªÉn sang grayscale\n",
    "    image = image.convert('L').resize((hash_size + 1, hash_size), Image.Resampling.LANCZOS)\n",
    "    pixels = np.asarray(image)\n",
    "    \n",
    "    # 2. T√≠nh ch√™nh l·ªách gi·ªØa c√°c pixel li·ªÅn k·ªÅ theo h√†ng ngang\n",
    "    diff = pixels[:, 1:] > pixels[:, :-1]\n",
    "    \n",
    "    # 3. Chuy·ªÉn boolean array sang hex string ƒë·ªÉ l√†m m√£ ƒë·ªãnh danh\n",
    "    return \"\".join([\"%1x\" % sum([2**i for i, v in enumerate(row) if v]) for row in diff])\n",
    "\n",
    "def find_duplicates(image_dir, threshold=2):\n",
    "    \"\"\"\n",
    "    T√¨m c√°c ·∫£nh tr√πng l·∫∑p ho·∫∑c g·∫ßn gi·ªëng nhau trong th∆∞ m·ª•c.\n",
    "    threshold: s·ªë l∆∞·ª£ng bit kh√°c bi·ªát t·ªëi ƒëa (0 l√† gi·ªëng h·ªát).\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    image_paths = list(image_dir.glob(\"*.[jJ][pP][gG]\")) + \\\n",
    "                  list(image_dir.glob(\"*.[jJ][pP][eE][gG]\")) + \\\n",
    "                  list(image_dir.glob(\"*.[pP][nN][gG]\")) + \\\n",
    "                  list(image_dir.glob(\"*.[wW][eE][bB][pP]\"))\n",
    "    \n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "    \n",
    "    print(f\"üîç ƒêang qu√©t {len(image_paths)} ·∫£nh trong {image_dir}...\")\n",
    "    \n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                h = dhash(img)\n",
    "                \n",
    "                # So s√°nh v·ªõi c√°c hash ƒë√£ l∆∞u\n",
    "                is_duplicate = False\n",
    "                for existing_hash, existing_path in hashes.items():\n",
    "                    # T√≠nh kho·∫£ng c√°ch Hamming (s·ªë l∆∞·ª£ng bit kh√°c nhau)\n",
    "                    distance = sum(c1 != c2 for c1, c2 in zip(h, existing_hash))\n",
    "                    \n",
    "                    if distance <= threshold:\n",
    "                        duplicates.append((path, existing_path, distance))\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "                \n",
    "                if not is_duplicate:\n",
    "                    hashes[h] = path\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω {path}: {e}\")\n",
    "            \n",
    "    return duplicates\n",
    "\n",
    "def main():\n",
    "    # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ·∫£nh c·ªßa b·∫°n ·ªü ƒë√¢y\n",
    "    target_dir = r\"d:\\Computer Vision\\Computer-Vision Project\\Computer-Vision-\\data\\images\\normal\"\n",
    "    \n",
    "    duplicates = find_duplicates(target_dir, threshold=2)\n",
    "    \n",
    "    if not duplicates:\n",
    "        print(\"Kh√¥ng t√¨m th·∫•y ·∫£nh tr√πng l·∫∑p!\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüì¢ T√¨m th·∫•y {len(duplicates)} c·∫∑p ·∫£nh t∆∞∆°ng ƒë·ªìng:\")\n",
    "    for dup, original, dist in duplicates:\n",
    "        print(f\"  - [{dist}] {dup.name} gi·ªëng v·ªõi {original.name}\")\n",
    "\n",
    "    confirm = input(\"\\nB·∫°n c√≥ mu·ªën x√≥a c√°c ·∫£nh tr√πng l·∫∑p n√†y kh√¥ng? (y/n): \")\n",
    "    if confirm.lower() == 'y':\n",
    "        for dup, original, dist in duplicates:\n",
    "            try:\n",
    "                os.remove(dup)\n",
    "                print(f\"ƒê√£ x√≥a: {dup.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\" Kh√¥ng th·ªÉ x√≥a {dup.name}: {e}\")\n",
    "        print(\"\\n ƒê√£ d·ªçn d·∫πp xong!\")\n",
    "    else:\n",
    "        print(\"\\n ƒê√£ h·ªßy l·ªánh x√≥a.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f7104",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
